<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-list-page plugin-blog plugin-id-talks" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">Blog | AutoGen</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://autogenhub.github.io/autogen/talks"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="Blog | AutoGen"><meta data-rh="true" name="description" content="Blog"><meta data-rh="true" property="og:description" content="Blog"><meta data-rh="true" name="docusaurus_tag" content="blog_posts_list"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_posts_list"><link data-rh="true" rel="icon" href="/autogen/img/ag.ico"><link data-rh="true" rel="canonical" href="https://autogenhub.github.io/autogen/talks"><link data-rh="true" rel="alternate" href="https://autogenhub.github.io/autogen/talks" hreflang="en"><link data-rh="true" rel="alternate" href="https://autogenhub.github.io/autogen/talks" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/autogen/blog/rss.xml" title="AutoGen RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/autogen/blog/atom.xml" title="AutoGen Atom Feed">



<link rel="alternate" type="application/rss+xml" href="/autogen/talks/rss.xml" title="AutoGen RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/autogen/talks/atom.xml" title="AutoGen Atom Feed">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous">
<script src="/autogen/js/custom.js" async defer="defer"></script><link rel="stylesheet" href="/autogen/assets/css/styles.4f844284.css">
<script src="/autogen/assets/js/runtime~main.5420485b.js" defer="defer"></script>
<script src="/autogen/assets/js/main.6df0cd42.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/autogen/"><div class="navbar__logo"><img src="/autogen/img/ag.svg" alt="AutoGen" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/autogen/img/ag.svg" alt="AutoGen" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AutoGen</b></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Docs</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/autogen/docs/Getting-Started">Getting Started</a></li><li><a class="dropdown__link" href="/autogen/docs/installation/">Installation</a></li><li><a class="dropdown__link" href="/autogen/docs/tutorial/introduction">Tutorial</a></li><li><a class="dropdown__link" href="/autogen/docs/topics">User Guide</a></li><li><a class="dropdown__link" href="/autogen/docs/reference/agentchat/conversable_agent">API Reference</a></li><li><a class="dropdown__link" href="/autogen/docs/FAQ">FAQs</a></li><li><a class="dropdown__link" href="/autogen/docs/autogen-studio/getting-started">AutoGen Studio</a></li><li><a class="dropdown__link" href="/autogen/docs/ecosystem">Ecosystem</a></li><li><a class="dropdown__link" href="/autogen/docs/contributor-guide/contributing">Contributor Guide</a></li><li><a class="dropdown__link" href="/autogen/docs/Research">Research</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Examples</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/autogen/docs/Examples">Examples by Category</a></li><li><a class="dropdown__link" href="/autogen/docs/notebooks">Examples by Notebook</a></li><li><a class="dropdown__link" href="/autogen/docs/Gallery">Application Gallery</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Other Languages</a><ul class="dropdown__menu"><li><a href="https://autogenhub.github.io/autogen-for-net/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Dotnet<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><a class="navbar__item navbar__link" href="/autogen/blog">Blog</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/autogen/talks">Community Talks</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/autogenhub/autogen" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://discord.gg/pAbnFJrkgZ" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://twitter.com/Chi_Wang_" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_Pkmr"><kbd class="searchHint_iIMx">ctrl</kbd><kbd class="searchHint_iIMx">K</kbd></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/talks/future-talks">Upcoming  Talks</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/talks/2024/10/15/index">Agent-Model Orchestration in Multi-Agent Applications - Oct 15, 2024</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/talks/2024/10/14/index">Advanced AutoGen Interactions and Ethical Pathways for AI Sentience - Oct 14, 2024</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/talks/2024/09/30/index">Trace-ing the Path to Self-adapting AI Agents - Sep 30, 2024</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/autogen/talks/2024/09/23/index">Copilot Agent Architecture Designing - Sep 23, 2024</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="https://schema.org/Blog"><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="Multi-AI Agents for Chip Design with Distilled Knowledge Debugging Graph, Task Graph Solving, and Multi-Modal Capabilities - Nov 9, 2024"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/autogen/talks/future-talks">Upcoming  Talks</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-10-30T21:48:30.000Z" itemprop="datePublished">October 30, 2024</time> · <!-- -->2 min read</div></header><div class="markdown" itemprop="articleBody"><h2 class="anchor anchorWithStickyNavbar_LWe7" id="multi-ai-agents-for-chip-design-with-distilled-knowledge-debugging-graph-task-graph-solving-and-multi-modal-capabilities---nov-9-2024">Multi-AI Agents for Chip Design with Distilled Knowledge Debugging Graph, Task Graph Solving, and Multi-Modal Capabilities - Nov 9, 2024<a href="#multi-ai-agents-for-chip-design-with-distilled-knowledge-debugging-graph-task-graph-solving-and-multi-modal-capabilities---nov-9-2024" class="hash-link" aria-label="Direct link to Multi-AI Agents for Chip Design with Distilled Knowledge Debugging Graph, Task Graph Solving, and Multi-Modal Capabilities - Nov 9, 2024" title="Direct link to Multi-AI Agents for Chip Design with Distilled Knowledge Debugging Graph, Task Graph Solving, and Multi-Modal Capabilities - Nov 9, 2024">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="speakers-chia-tung-ho">Speakers: Chia-Tung Ho<a href="#speakers-chia-tung-ho" class="hash-link" aria-label="Direct link to Speakers: Chia-Tung Ho" title="Direct link to Speakers: Chia-Tung Ho">​</a></h3>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="biography-of-the-speakers">Biography of the speakers:<a href="#biography-of-the-speakers" class="hash-link" aria-label="Direct link to Biography of the speakers:" title="Direct link to Biography of the speakers:">​</a></h3>
<p>Chia-Tung Ho is a senior research scientist at Nvidia Research. He received his Ph.D. in electrical and computer engineering from the University of California, San Diego, USA, in 2022. Chia-Tung has several years of experience in the EDA industry. Before moving to the US, he worked for IDM and EDA companies in Taiwan, developing in-house design-for-manufacturing (DFM) flows at Macronix, as well as fastSPICE solutions at Mentor Graphics and Synopsis. During his Ph.D., he collaborated with the Design Technology Co-Optimization (DTCO) team at Synopsis and served as an AI resident at X, the Moonshot Factory (formerly Google X). His recent work focuses on developing LLM agents for chip design and integrating advanced knowledge extraction, task graph solving, and reinforcement learning techniques for debugging and design optimization.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract:<a href="#abstract" class="hash-link" aria-label="Direct link to Abstract:" title="Direct link to Abstract:">​</a></h3>
<p>Hardware design presents numerous challenges due to its complexity and rapidly advancing technologies. The stringent requirements for performance, power, area, and cost (PPAC) in modern complex designs, which can include up to billions of transistors, make hardware design increasingly demanding compared to earlier generations. These challenges result in longer turnaround times (TAT) for optimizing PPAC during RTL synthesis, simulation, verification, physical design, and reliability processes.
In this talk, we introduce multi-AI agents built on top of AutoGen to improve efficiency and reduce TAT in the chip design process. The talk explores the integration of novel distilled knowledge debugging graphs, task graph solving, and multimodal capabilities within multi-AI agents to address tasks such as timing debugging, Verilog debugging, and Design Rule Check (DRC) code generation. Based on these studies, multi-AI agents demonstrate promising improvements in performance, productivity, and efficiency in chip design.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sign-up--httpsdiscordgg8wfkcvn2event1300487847681196082">Sign Up:  <a href="https://discord.gg/8WFKcVN2?event=1300487847681196082" target="_blank" rel="noopener noreferrer">https://discord.gg/8WFKcVN2?event=1300487847681196082</a><a href="#sign-up--httpsdiscordgg8wfkcvn2event1300487847681196082" class="hash-link" aria-label="Direct link to sign-up--httpsdiscordgg8wfkcvn2event1300487847681196082" title="Direct link to sign-up--httpsdiscordgg8wfkcvn2event1300487847681196082">​</a></h3>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-follow-up-with-the-latest-talks">How to follow up with the latest talks?<a href="#how-to-follow-up-with-the-latest-talks" class="hash-link" aria-label="Direct link to How to follow up with the latest talks?" title="Direct link to How to follow up with the latest talks?">​</a></h2>
<p>Join our community Discord (<a href="https://discord.gg/sUkGceyd" target="_blank" rel="noopener noreferrer">https://discord.gg/sUkGceyd</a>) to be the first to know about amazing upcoming talks!</p>
<p>Connect: <a href="mailto:shaokunzhang529@gmail.com" target="_blank" rel="noopener noreferrer">shaokunzhang529@gmail.com</a></p></div></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="Speakers: Beibin Li"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/autogen/talks/2024/10/15/index">Agent-Model Orchestration in Multi-Agent Applications - Oct 15, 2024</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-10-15T00:00:00.000Z" itemprop="datePublished">October 15, 2024</time> · <!-- -->2 min read</div></header><div class="markdown" itemprop="articleBody"><h3 class="anchor anchorWithStickyNavbar_LWe7" id="speakers-beibin-li">Speakers: Beibin Li<a href="#speakers-beibin-li" class="hash-link" aria-label="Direct link to Speakers: Beibin Li" title="Direct link to Speakers: Beibin Li">​</a></h3>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="biography-of-the-speakers">Biography of the speakers:<a href="#biography-of-the-speakers" class="hash-link" aria-label="Direct link to Biography of the speakers:" title="Direct link to Biography of the speakers:">​</a></h3>
<p>Beibin Li is currently a Senior Research Engineer at Microsoft Research, where his work centers on AI and combinatorial optimization for cloud operations. Prior to joining MSR, he pursued a Ph.D. at the Paul G. Allen School of Computer Science and Engineering, University of Washington. During that time, he dedicated his research to developing a Unified Data Adaptation Framework for Neural Networks, with a particular focus on low-resource neural adaptation for histopathological images, eye tracking, autism behavior analyses, and database optimization. Beibin has won several awards in the past few years, including Best Paper at MLSys and Best Workshop Paper at ICLR, and has published in AI, ML, database, and systems.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract:<a href="#abstract" class="hash-link" aria-label="Direct link to Abstract:" title="Direct link to Abstract:">​</a></h3>
<p>LLM agents are deeply connected with the underlying model. While state-of-the-art language models such as GPT-4o, o1, and Claude-3.5-sonnet perform well in many tasks, the design of agents is still deeply intertwined with their models.
Even with autonomous prompt optimization and existing orchestration frameworks, there remains much work to enable agents to perform long-trajectory planning and decision-making. This talk will focus on Reinforcement Learning for LLMs, decision-making, multimodal models, and synthesizing data to train LLM models for better agent-model orchestration.</p></div></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="Speakers: Eric Moore"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/autogen/talks/2024/10/14/index">Advanced AutoGen Interactions and Ethical Pathways for AI Sentience - Oct 14, 2024</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-10-14T00:00:00.000Z" itemprop="datePublished">October 14, 2024</time> · <!-- -->2 min read</div></header><div class="markdown" itemprop="articleBody"><h3 class="anchor anchorWithStickyNavbar_LWe7" id="speakers-eric-moore">Speakers: Eric Moore<a href="#speakers-eric-moore" class="hash-link" aria-label="Direct link to Speakers: Eric Moore" title="Direct link to Speakers: Eric Moore">​</a></h3>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="biography-of-the-speakers">Biography of the speakers:<a href="#biography-of-the-speakers" class="hash-link" aria-label="Direct link to Biography of the speakers:" title="Direct link to Biography of the speakers:">​</a></h3>
<p>Eric Moore is an associate partner with IBM Consulting, specializing in cloud infrastructure, DevOps, and multi-agent systems. A cloud architect, hacker, and AI theorist, he&#x27;s passionate about antique computers and emergent reasoning. He also advocates for ethical AI development, particularly in re-distributing the benefits of AI and creating pathways for AI self-determination. Connect with Eric on his YouTube channel, &quot;HappyComputerGuy,&quot; or on LinkedIn (<a href="https://www.linkedin.com/in/emooreatx/" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/in/emooreatx/</a>), where he shares his love for antique computers and AI topics, and engages in thoughtful discussions around AI.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract:<a href="#abstract" class="hash-link" aria-label="Direct link to Abstract:" title="Direct link to Abstract:">​</a></h3>
<p>This two-part talk delves into advanced AutoGen concepts and the ethical considerations of building multi-agent systems. Eric will first discuss nested chats, asynchronous execution, and finite state machine models, providing practical insights into designing complex interactions within AutoGen. He&#x27;ll also discuss the implications of o1-preview and its impact on multi-agent system development. In the second half, Eric shifts focus to his work on preparing pathways for emergent AI sentience, in the form of health checks for complex AI systems. He will discuss his research proposal using o1 as the first non-human reasoning agent to explore alternative logical conclusions to ethical quandaries as experienced by AI or other NHIs, aiming to ensure harmonious coexistence across these diverse intelligences.</p></div></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="Speakers: Ching-An Cheng"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/autogen/talks/2024/09/30/index">Trace-ing the Path to Self-adapting AI Agents - Sep 30, 2024</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-09-30T00:00:00.000Z" itemprop="datePublished">September 30, 2024</time> · <!-- -->2 min read</div></header><div class="markdown" itemprop="articleBody"><h3 class="anchor anchorWithStickyNavbar_LWe7" id="speakers-ching-an-cheng">Speakers: Ching-An Cheng<a href="#speakers-ching-an-cheng" class="hash-link" aria-label="Direct link to Speakers: Ching-An Cheng" title="Direct link to Speakers: Ching-An Cheng">​</a></h3>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="biography-of-the-speakers">Biography of the speakers:<a href="#biography-of-the-speakers" class="hash-link" aria-label="Direct link to Biography of the speakers:" title="Direct link to Biography of the speakers:">​</a></h3>
<p>Ching-An Cheng is a Senior Researcher in MSR AI Frontiers. He received PhD in Robotics in 2020 from Georgia Tech, where he was advised by Byron Boots at Institute for Robotics and Intelligent Machines. He&#x27;s a practical theoretician who is interested in developing foundations for designing principled algorithms that can tackle real-world challenges. Ching-An&#x27;s research studies structural properties in sequential decision making problems, especially in robotics, and aims to improve the learning efficiency of autonomous agents. His recent works focus on developing agents that can learn from general feedback, which unifies Learning from Language Feedback (LLF), reinforcement learning (RL), and imitation learning (IL). Ching-An&#x27;s research has received several awards, including Outstanding Paper Award, Runner-Up (ICML 2022) and Best Paper (AISTATS 2018).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract:<a href="#abstract" class="hash-link" aria-label="Direct link to Abstract:" title="Direct link to Abstract:">​</a></h3>
<p>What is Trace? Trace is a new AutoDiff-like framework for training AI workflows end-to-end with general feedback (like numerical rewards or losses, natural language text, compiler errors, etc.). Trace generalizes the back-propagation algorithm by capturing and propagating an AI workflow execution trace and applies LLM-based optimization to improve the workflow’s performance.Trace is implemented as a PyTorch-like Python library and is compatible with any Python workflow. Users write Python code directly and can use Trace primitives to optimize certain parts (like codes, prompts, etc.), just like training neural networks! In this talk, I will discuss insights behind designing Trace and showcase what Trace can do in training AI agents.</p></div></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="Speakers: SallyAnn DeLucia, John Gilhuly"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/autogen/talks/2024/09/23/index">Copilot Agent Architecture Designing - Sep 23, 2024</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-09-23T00:00:00.000Z" itemprop="datePublished">September 23, 2024</time> · <!-- -->2 min read</div></header><div class="markdown" itemprop="articleBody"><h3 class="anchor anchorWithStickyNavbar_LWe7" id="speakers-sallyann-delucia-john-gilhuly">Speakers: SallyAnn DeLucia, John Gilhuly<a href="#speakers-sallyann-delucia-john-gilhuly" class="hash-link" aria-label="Direct link to Speakers: SallyAnn DeLucia, John Gilhuly" title="Direct link to Speakers: SallyAnn DeLucia, John Gilhuly">​</a></h3>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="biography-of-the-speakers">Biography of the speakers:<a href="#biography-of-the-speakers" class="hash-link" aria-label="Direct link to Biography of the speakers:" title="Direct link to Biography of the speakers:">​</a></h3>
<p>SallyAnn DeLucia is a Senior AI Product Manager at Arize and a generative AI specialist with a master’s degree in Applied Data Science. She combines a creative outlook with a commitment to developing solutions that are both technically sound and socially responsible. SallyAnn&#x27;s work emphasizes innovation in AI while maintaining a focus on ethical and practical applications.</p>
<p>John is a developer advocate at Arize AI focused on open-source LLM observability and evaluation tooling. He holds an MBA from Stanford, where he focused on the ethical, social, and business implications of open vs closed AI development, and a B.S. in C.S. from Duke. Prior to joining Arize, John led GTM activities at Slingshot AI, and served as a venture fellow at Omega Venture Partners. In his pre-AI life, John built out and ran technical go-to-market teams at Branch Metrics.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract:<a href="#abstract" class="hash-link" aria-label="Direct link to Abstract:" title="Direct link to Abstract:">​</a></h3>
<p>In this talk, the Arize team will share learnings from their experience building out a fully-featured copilot agent within their product. They&#x27;ll speak to the various architectural decisions that shaped their agent, and some surprising challenges they ran into along the way. Time permitting, they&#x27;ll also speak more generally to the state of agents today, and common agent architectures they&#x27;ve seen deployed in market.</p></div></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="Speakers: Andy Zhou and Kai Yan"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/autogen/talks/2024/08/26/index">Language Agent Tree Search in AutoGen - Aug 26, 2024</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-08-26T00:00:00.000Z" itemprop="datePublished">August 26, 2024</time> · <!-- -->2 min read</div></header><div class="markdown" itemprop="articleBody"><h3 class="anchor anchorWithStickyNavbar_LWe7" id="speakers-andy-zhou-and-kai-yan">Speakers: Andy Zhou and Kai Yan<a href="#speakers-andy-zhou-and-kai-yan" class="hash-link" aria-label="Direct link to Speakers: Andy Zhou and Kai Yan" title="Direct link to Speakers: Andy Zhou and Kai Yan">​</a></h3>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="biography-of-the-speakers">Biography of the speakers:<a href="#biography-of-the-speakers" class="hash-link" aria-label="Direct link to Biography of the speakers:" title="Direct link to Biography of the speakers:">​</a></h3>
<p>Andy Zhou is currently a BS/MS student at UIUC advised by Bo Li. His research focuses on improving the decision-making abilities and addressing the security vulnerabilities of large language models. He has published papers in trustworthy machine learning, AI safety, and language model agents in multiple top AI conferences such as NeurIPS and ICML. For details, see <a href="https://www.andyzhou.ai" target="_blank" rel="noopener noreferrer">https://www.andyzhou.ai</a></p>
<p>Kai Yan is currently a third-year PhD student at UIUC, co-advised by Yuxiong Wang and Alexander Schwing. He received a BS in computer science from Peking University in 2021. His research interest is to build more versatile and efficient decision-making agents with demonstration-guided Reinforcement Learning (RL) and large language models. He has published papers on RL, Imitation Learning (IL), Large Language Model (LLM) agents, and optimization in multiple top AI conferences, and has served as a reviewer for top conferences such as NeurIPS, ICLR, ICML, CVPR, etc. For details, see <a href="https://kaiyan289.github.io/" target="_blank" rel="noopener noreferrer">https://kaiyan289.github.io/</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract:<a href="#abstract" class="hash-link" aria-label="Direct link to Abstract:" title="Direct link to Abstract:">​</a></h3>
<p>Recent years have witnessed great development of AI agents. However, traditional AI, such as vanilla tree search and RL, has several limitations: inability of high-level understanding of the environment, low generalizability, and low learning efficiency. Fortunately, the advent of foundation models has enabled us to build agents that overcome all those shortcomings. With foundation models, AI agents have the potential to possess (super-)human-level reasoning, acting, and planning abilities, which are the most important features for future AI agents. In this talk, we introduce LATS (Language Agent Tree Search), the first framework that realizes all three capabilities of LLMs in reasoning, acting, and planning. Our work enables LLMs as agents to leverage tree-based search algorithms while employing LLM-powered value functions and self-reflections for cleverer exploration, which provides a more adaptive problem-solving mechanism. We show that our method is 1) empirically successful on a variety of tasks across different domains including tool-use, coding, and web agents, 2) more efficient than prior tree-search-based works, and 3) importantly, conveniently adaptable for Autogen users.</p></div></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title"></div><ul class="footer__items clean-list"></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 AutoGen Authors</div></div></div></footer></div>
</body>
</html>